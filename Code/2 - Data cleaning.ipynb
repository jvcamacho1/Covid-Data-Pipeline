{"cells":[{"cell_type":"markdown","source":["## 2- Data clean and standardize"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"453e64a7-b1ce-4b44-8d45-f2a3a41125d8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import when, regexp_replace, col, trim, to_date\n\ndestination_path = '/FileStore/tables/Covid-USA/raw/daily_cases_raw'\nspark = SparkSession.builder.appName(\"COVID Tracking Data - Data cleaning\").getOrCreate()\ndf = spark.read.format(\"parquet\").load(destination_path)\ndf = df.select(\"date\",\"state\", \"positive\", \"death\", \"totalTestsViral\")\n\ndf = df.withColumn(\"state\", trim(df.state))\n\n\ndf = df.withColumn(\"positive\", when(col(\"positive\").isNull(), 0).otherwise(col(\"positive\")))\ndf = df.withColumn(\"death\", when(col(\"death\").isNull(), 0).otherwise(col(\"death\")))\n\naverage_tests = df.selectExpr(\"avg(totalTestsViral)\").collect()[0][0]\ndf = df.withColumn(\"totalTestsViral\", when(col(\"totalTestsViral\").isNull(), average_tests).otherwise(col(\"totalTestsViral\")))\ndf = df.withColumn('date', to_date(df['date'], 'yyyyMMdd'))\n\ndestination_path = '/FileStore/tables/Covid-USA/bronze/daily_cases_bronze'\ndf.write.mode('overwrite').format(\"parquet\").save(destination_path)\n\nspark.stop()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c41d2a1-ed60-4f78-a5b0-b71ade67ba0c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Data cleaning","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3296677439647233}},"nbformat":4,"nbformat_minor":0}
